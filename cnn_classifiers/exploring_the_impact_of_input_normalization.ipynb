{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demystifying Input Image Pixel Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    " 1. [Outline](#outline)\n",
    " 2. [MNIST Classifcation Task](#mnists_task)\n",
    " 3. [CIFAR-10 Classification Task](#cifar10_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='outline'></a>\n",
    "# Outline\n",
    "\n",
    "When dealing with images as well as other inputs to a deep neural network, it is important to normalize the pixel values. There are two main conventions: normalization to the range -1.0 to 1.0 and normalization to the range 0.0 to 1.0. \n",
    "\n",
    "The goal of this notebook is to explore this and find a way to train a netwrok without pixel normalization. First, the pixel normalization will be explored emperically in the context of the  MNIST and CIFAR-10 classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.dirname(os.getcwd())\n",
    ")\n",
    "from utilities.tile_image_plot_utilities import\\\n",
    "    custom_tile_image_plot,\\\n",
    "    custom_tile_plot_with_inference_hists\n",
    "from utilities.generator_utilities import ScrambledImageDataGenerator\n",
    "from utilities.keras_callback_utilities import CustomHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mnist_task'></a>\n",
    "<br><br><br>\n",
    "\n",
    "----\n",
    "# MNIST Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(\"Train data:   \", mnist_train[0].shape)\n",
    "print(\"Train labels: \", mnist_train[1].shape)\n",
    "print(\"Test data:    \", mnist_test[0].shape)\n",
    "print(\"Test labels:  \", mnist_test[1].shape)\n",
    "print(\"--\"*16)\n",
    "print(f\"Train data range: ({np.amin(mnist_train[0])}, {np.amax(mnist_train[0])})\")\n",
    "print(f\"Test data range:  ({np.amin(mnist_test[0])}, {np.amax(mnist_test[0])})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a Model\n",
    "\n",
    "The model architecture is LeNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model:\n",
    "tf.keras.backend.clear_session()\n",
    "activation = \"relu\" # \"sigmoid\" \n",
    "mnist_model = tf.keras.Sequential(name=\"MNIST\")\n",
    "mnist_model.add(\n",
    "    tf.keras.Input(shape=(28, 28, 1), batch_size=None, name=\"input\")\n",
    ")\n",
    "mnist_model.add(\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=6, \n",
    "        kernel_size=(5, 5), \n",
    "        strides=(1, 1), \n",
    "        activation=activation, \n",
    "        padding=\"same\", \n",
    "        name=\"conv_1\")\n",
    ")\n",
    "mnist_model.add(\n",
    "    tf.keras.layers.AvgPool2D(pool_size=2, strides=2)\n",
    ")\n",
    "mnist_model.add(\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=16, \n",
    "        kernel_size=(5, 5), \n",
    "        strides=(1, 1), \n",
    "        activation=activation, \n",
    "        padding=\"valid\", \n",
    "        name=\"conv_2\")\n",
    ")\n",
    "mnist_model.add(\n",
    "    tf.keras.layers.AvgPool2D(pool_size=2, strides=2)\n",
    ")\n",
    "mnist_model.add(\n",
    "    tf.keras.layers.Flatten()\n",
    ")\n",
    "mnist_model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        120, \n",
    "        activation=activation,\n",
    "        name=\"dense_1\")\n",
    ")\n",
    "mnist_model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        84, \n",
    "        activation=activation,\n",
    "        name=\"dense_2\")\n",
    ")\n",
    "mnist_model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        10, \n",
    "        activation=\"softmax\",\n",
    "        name=\"dense_3\")\n",
    ")\n",
    "\n",
    "# Compile model:\n",
    "mnist_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")]\n",
    ")\n",
    "\n",
    "# Print model summary:\n",
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = not True\n",
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "\n",
    "data_generator = ScrambledImageDataGenerator(\n",
    "    features=mnist_train[0][:, : ,: , np.newaxis],\n",
    "    labels=mnist_train[1],\n",
    "    batch_size=batch_size,\n",
    "    scrambler_array=None,\n",
    "    normalize=normalize)\n",
    "\n",
    "custom_history = CustomHistory()\n",
    "\n",
    "fit_history = mnist_model.fit(\n",
    "    data_generator,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        custom_history,\n",
    "        tf.keras.callbacks.History()],\n",
    "    initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = fit_history.history[\"loss\"]\n",
    "accuracy = fit_history.history[\"accuracy\"]\n",
    "epochs = np.arange(1, len(loss)+1)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10., 6.))\n",
    "ax2 = ax1.twinx()\n",
    "#\n",
    "color = \"blue\"\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Cross-entropy\", fontsize=14., color=color)\n",
    "ax1.plot(epochs, loss, ls=\"--\", marker=\"d\", color=color)\n",
    "ax1.tick_params(axis=\"y\", labelcolor=color)\n",
    "ax1.set_xticks(epochs)\n",
    "ax1.xaxis.grid()\n",
    "ax1.set_ylim(bottom=0.0)\n",
    "ax1.set_yscale(\"linear\")\n",
    "#\n",
    "color = \"gray\"\n",
    "ax2.set_ylabel(\"Accuracy\", fontsize=14., color=color)\n",
    "ax2.plot(epochs, accuracy, ls=\"--\", marker=\"d\", color=color)\n",
    "ax2.tick_params(axis=\"y\", labelcolor=color)\n",
    "ax2.set_ylim(0.0, 1.0)\n",
    "#\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = custom_history.get_loss_history()\n",
    "epochs_list = list(loss_history.keys())\n",
    "losses_array = np.array(list(loss_history.values())).flatten()\n",
    "num_epochs = len(epochs_list)\n",
    "num_points = int(np.prod(losses_array.shape))\n",
    "num_batches = num_points // num_epochs\n",
    "print(f\"\\tNumber of Epochs: {num_epochs}\")\n",
    "print(f\"\\tEpoch Size:       {num_batches}\")\n",
    "#\n",
    "fig = plt.figure(figsize=(16., 8.))\n",
    "x = np.linspace(\n",
    "    start=epochs_list[0], \n",
    "    stop=epochs_list[-1]+1, \n",
    "    num=num_points, \n",
    "    endpoint=False)\n",
    "plt.plot(x, losses_array, ls=\"-\", lw=1.0, color=\"royalblue\")\n",
    "plt.xticks(epochs_list, labels=epochs_list)\n",
    "plt.title(\"Full Training History\", fontsize=14., fontweight=\"bold\")\n",
    "plt.ylabel(\"Loss (CE)\", fontsize=12., fontweight=\"bold\", color=\"gray\")\n",
    "plt.xlabel(\"Epochs\", fontsize=12., fontweight=\"bold\", color=\"gray\")\n",
    "plt.grid()\n",
    "plt.gca().set_axisbelow(True)\n",
    "#plt.yscale(\"symlog\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cifar10_task'></a>\n",
    "<br><br><br>\n",
    "\n",
    "----\n",
    "# CIFAR-10 Classifcation Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_train, cifar10_test = tf.keras.datasets.cifar10.load_data()\n",
    "print(\"Train data:   \", cifar10_train[0].shape)\n",
    "print(\"Train labels: \", cifar10_train[1].shape)\n",
    "print(\"Test data:    \", cifar10_test[0].shape)\n",
    "print(\"Test labels:  \", cifar10_test[1].shape)\n",
    "print(\"--\"*16)\n",
    "print(f\"Train data range: ({np.amin(cifar10_train[0])}, {np.amax(cifar10_train[0])})\")\n",
    "print(f\"Test data range:  ({np.amin(cifar10_test[0])}, {np.amax(cifar10_test[0])})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a Model\n",
    "\n",
    "A CNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model:\n",
    "tf.keras.backend.clear_session()\n",
    "activation = \"relu\" # \"sigmoid\"\n",
    "cifar10_model = tf.keras.Sequential(name=\"CIFAR-10\")\n",
    "cifar10_model.add(\n",
    "    tf.keras.Input(shape=(32, 32, 3), batch_size=None, name=\"input\")\n",
    ")\n",
    "cifar10_model.add(\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=6, \n",
    "        kernel_size=(5, 5), \n",
    "        strides=(1, 1), \n",
    "        activation=activation, \n",
    "        padding=\"same\", \n",
    "        name=\"conv_1\")\n",
    ")\n",
    "cifar10_model.add(\n",
    "    tf.keras.layers.AvgPool2D(pool_size=2, strides=2)\n",
    ")\n",
    "cifar10_model.add(\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=16, \n",
    "        kernel_size=(5, 5), \n",
    "        strides=(1, 1), \n",
    "        activation=activation, \n",
    "        padding=\"valid\", \n",
    "        name=\"conv_2\")\n",
    ")\n",
    "cifar10_model.add(\n",
    "    tf.keras.layers.AvgPool2D(pool_size=2, strides=2)\n",
    ")\n",
    "cifar10_model.add(\n",
    "    tf.keras.layers.Flatten()\n",
    ")\n",
    "cifar10_model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        120, \n",
    "        activation=activation,\n",
    "        name=\"dense_1\")\n",
    ")\n",
    "cifar10_model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        84, \n",
    "        activation=activation,\n",
    "        name=\"dense_2\")\n",
    ")\n",
    "cifar10_model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        10, \n",
    "        activation=\"softmax\",\n",
    "        name=\"dense_3\")\n",
    ")\n",
    "\n",
    "# Compile model:\n",
    "cifar10_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")]\n",
    ")\n",
    "\n",
    "# Print model summary:\n",
    "cifar10_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = True\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "\n",
    "data_generator = ScrambledImageDataGenerator(\n",
    "    features=cifar10_train[0],\n",
    "    labels=cifar10_train[1],\n",
    "    batch_size=batch_size,\n",
    "    scrambler_array=None,\n",
    "    normalize=normalize)\n",
    "\n",
    "custom_history = CustomHistory()\n",
    "\n",
    "fit_history = cifar10_model.fit(\n",
    "    data_generator,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        custom_history,\n",
    "        tf.keras.callbacks.History()],\n",
    "    initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = fit_history.history[\"loss\"]\n",
    "accuracy = fit_history.history[\"accuracy\"]\n",
    "epochs = np.arange(1, len(loss)+1)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10., 6.))\n",
    "ax2 = ax1.twinx()\n",
    "#\n",
    "color = \"blue\"\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Cross-entropy\", fontsize=14., color=color)\n",
    "ax1.plot(epochs, loss, ls=\"--\", marker=\"d\", color=color)\n",
    "ax1.tick_params(axis=\"y\", labelcolor=color)\n",
    "ax1.set_xticks(epochs)\n",
    "ax1.xaxis.grid()\n",
    "ax1.set_ylim(bottom=0.0)\n",
    "ax1.set_yscale(\"linear\")\n",
    "#\n",
    "color = \"gray\"\n",
    "ax2.set_ylabel(\"Accuracy\", fontsize=14., color=color)\n",
    "ax2.plot(epochs, accuracy, ls=\"--\", marker=\"d\", color=color)\n",
    "ax2.tick_params(axis=\"y\", labelcolor=color)\n",
    "ax2.set_ylim(0.0, 1.0)\n",
    "#\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = custom_history.get_loss_history()\n",
    "epochs_list = list(loss_history.keys())\n",
    "losses_array = np.array(list(loss_history.values())).flatten()\n",
    "num_epochs = len(epochs_list)\n",
    "num_points = int(np.prod(losses_array.shape))\n",
    "num_batches = num_points // num_epochs\n",
    "print(f\"\\tNumber of Epochs: {num_epochs}\")\n",
    "print(f\"\\tEpoch Size:       {num_batches}\")\n",
    "#\n",
    "fig = plt.figure(figsize=(16., 8.))\n",
    "x = np.linspace(\n",
    "    start=epochs_list[0], \n",
    "    stop=epochs_list[-1]+1, \n",
    "    num=num_points, \n",
    "    endpoint=False)\n",
    "plt.plot(x, losses_array, ls=\"-\", lw=1.0, color=\"royalblue\")\n",
    "plt.xticks(epochs_list, labels=epochs_list)\n",
    "plt.title(\"Full Training History\", fontsize=14., fontweight=\"bold\")\n",
    "plt.ylabel(\"Loss (CE)\", fontsize=12., fontweight=\"bold\", color=\"gray\")\n",
    "plt.xlabel(\"Epochs\", fontsize=12., fontweight=\"bold\", color=\"gray\")\n",
    "plt.grid()\n",
    "plt.gca().set_axisbelow(True)\n",
    "#plt.yscale(\"symlog\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
