{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Effect of Scrambling Image on Training CNN-Based Classifiers  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents:\n",
    "\n",
    " 1. [Outline](#outline)\n",
    " 2. [MNIST Dataset](#mnist_ds)\n",
    " 3. [Fashion-MNIST Dataset](#fashion_mnist_ds)\n",
    " 4. [CIFAR-10 Dataset](#cifar10_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='outline'></a>\n",
    "# Outline\n",
    "\n",
    "Here we explore the effect of a random scrambling of the input image (shuffling pixels pixels) on classification in three tasks: case  \n",
    " - MNIST\n",
    " - Fashion-MNIST\n",
    " - CIFAR10\n",
    "\n",
    "First, we expect no effect on fully-connected networks. For CNN-based networks, this is expected to significantly interfere with the networks ability to learn. An interesting question that one can ask is whether or not the classification ability of a CNN-network can be recovered by making the network deeper and narrower at the same time to increase the receptive fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.dirname(os.getcwd())\n",
    ")\n",
    "from utilities.tile_image_plot_utilities import\\\n",
    "    custom_tile_image_plot,\\\n",
    "    custom_tile_plot_with_inference_hists\n",
    "from utilities.generator_utilities import ScrambledImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mnist_ds'></a>\n",
    "<br><br><br>\n",
    "\n",
    "------\n",
    "# MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test and train features and labels for the MNIST dataset:\n",
    "mnist = tf.keras.datasets.mnist\n",
    "mnist_train, mnist_test = mnist.load_data()\n",
    "\n",
    "# Check the type and size of the test and train features and labels:\n",
    "print(\"Train data:   \", mnist_train[0].shape)\n",
    "print(\"Train labels: \", mnist_train[1].shape)\n",
    "print(\"Test data:    \", mnist_test[0].shape)\n",
    "print(\"Test labels:  \", mnist_test[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16., 8.))\n",
    "bins = np.linspace(start=-0.5, stop=9.5, num=11, endpoint=True)\n",
    "bar_heights, _, _ = plt.hist(mnist_train[1], bins=bins, \n",
    "         color=\"royalblue\", edgecolor=\"black\", alpha=0.8, \n",
    "         rwidth=0.9, align=\"mid\", label=\"Train\")\n",
    "plt.hist(mnist_test[1], bins=bins, bottom=bar_heights,\n",
    "         color=\"salmon\", edgecolor=\"black\", alpha=0.8, \n",
    "         rwidth=0.9, align=\"mid\", label=\"Test\")\n",
    "plt.xticks(np.arange(10), labels=np.arange(10), \n",
    "           fontsize=14., fontweight=\"normal\")\n",
    "plt.legend(fontsize=14.)\n",
    "plt.title(\"MNIST Dataset\", fontsize=16., fontweight=\"bold\")\n",
    "plt.grid()\n",
    "plt.gca().set_axisbelow(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unscrambled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some of the images:\n",
    "image_gen = ScrambledImageDataGenerator( \n",
    "    features=mnist_train[0][0:256, :, :, np.newaxis],\n",
    "    labels=mnist_train[1][0:256],\n",
    "    batch_size=255,\n",
    "    scrambler_array=None,\n",
    "    normalize=False)\n",
    "\n",
    "custom_tile_image_plot( \n",
    "    (15,15),\n",
    "    image_gen[0][0],\n",
    "    labels=image_gen[0][1],\n",
    "    label_size=28.,\n",
    "    label_color=\"red\",\n",
    "    filename=\"\",\n",
    "    figure_size=(16., 16.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scramble Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scrampled images:\n",
    "num_pixels = 28 * 28\n",
    "scrambler = np.linspace(\n",
    "    start=0, stop=num_pixels, num=num_pixels, \n",
    "    endpoint=False, dtype=np.int32)\n",
    "np.random.shuffle(scrambler)\n",
    "\n",
    "scrambled_image_gen = ScrambledImageDataGenerator(\n",
    "    features=mnist_train[0][0:256, :, :, np.newaxis],\n",
    "    labels=mnist_train[1][0:256],\n",
    "    batch_size=255,\n",
    "    scrambler_array=scrambler,\n",
    "    normalize=False)\n",
    " \n",
    "custom_tile_image_plot( \n",
    "    (15,15),\n",
    "    scrambled_image_gen[0][0],\n",
    "    labels=scrambled_image_gen[0][1],\n",
    "    label_size=28.,\n",
    "    label_color=\"red\",\n",
    "    filename=\"\",\n",
    "    figure_size=(16., 16.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fashion_mnist_ds'></a>\n",
    "<br><br><br>\n",
    "\n",
    "----\n",
    "# Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test and train features and labels for the MNIST dataset:\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "fmnist_train, fmnist_test = fashion_mnist.load_data()\n",
    "\n",
    "# Check the type and size of the test and train features and labels:\n",
    "print(\"Train data:   \", fmnist_train[0].shape)\n",
    "print(\"Train labels: \", fmnist_train[1].shape)\n",
    "print(\"Test data:    \", fmnist_test[0].shape)\n",
    "print(\"Test labels:  \", fmnist_test[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16., 8.))\n",
    "bins = np.linspace(start=-0.5, stop=9.5, num=11, endpoint=True)\n",
    "bar_heights, _, _ = plt.hist(fmnist_train[1], bins=bins, \n",
    "         color=\"royalblue\", edgecolor=\"black\", alpha=0.8, \n",
    "         rwidth=0.9, align=\"mid\", label=\"Train\")\n",
    "plt.hist(fmnist_test[1], bins=bins, bottom=bar_heights,\n",
    "         color=\"salmon\", edgecolor=\"black\", alpha=0.8, \n",
    "         rwidth=0.9, align=\"mid\", label=\"Test\")\n",
    "plt.xticks(np.arange(10), labels=np.arange(10), \n",
    "           fontsize=14., fontweight=\"normal\")\n",
    "plt.legend(fontsize=14.)\n",
    "plt.title(\"Fashion MNIST Dataset\", fontsize=16., fontweight=\"bold\")\n",
    "plt.grid()\n",
    "plt.gca().set_axisbelow(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unscrambled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some of the images:\n",
    "image_gen = ScrambledImageDataGenerator( \n",
    "    features=fmnist_train[0][0:256,:,:],\n",
    "    labels=fmnist_train[1][0:256],\n",
    "    batch_size=255,\n",
    "    scrambler_array=None,\n",
    "    normalize=False)\n",
    "\n",
    "custom_tile_image_plot( \n",
    "    (15,15),\n",
    "    image_gen[0][0],\n",
    "    labels=image_gen[0][1],\n",
    "    label_size=28.,\n",
    "    label_color=\"red\",\n",
    "    filename=\"\",\n",
    "    figure_size=(16., 16.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrambled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scrampled images:\n",
    "num_pixels = 28 * 28\n",
    "scrambler = np.linspace(\n",
    "    start=0, stop=num_pixels, num=num_pixels, \n",
    "    endpoint=False, dtype=np.int32)\n",
    "np.random.shuffle(scrambler)\n",
    "\n",
    "scrambled_image_gen = ScrambledImageDataGenerator(\n",
    "    features=fmnist_train[0][0:256,:,:],\n",
    "    labels=fmnist_train[1][0:256],\n",
    "    batch_size=255,\n",
    "    scrambler_array=scrambler,\n",
    "    normalize=False)\n",
    " \n",
    "custom_tile_image_plot( \n",
    "    (15,15),\n",
    "    scrambled_image_gen[0][0],\n",
    "    labels=scrambled_image_gen[0][1],\n",
    "    label_size=28.,\n",
    "    label_color=\"red\",\n",
    "    filename=\"\",\n",
    "    figure_size=(16., 16.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cifar10_ds'></a>\n",
    "<br><br><br>\n",
    "\n",
    "----\n",
    "# CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test and train features and labels for the MNIST dataset:\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "cifar10_train, cifar10_test = cifar10.load_data()\n",
    "\n",
    "# Check the type and size of the test and train features and labels:\n",
    "print(\"Train data:   \", cifar10_train[0].shape)\n",
    "print(\"Train labels: \", cifar10_train[1].shape)\n",
    "print(\"Test data:    \", cifar10_test[0].shape)\n",
    "print(\"Test labels:  \", cifar10_test[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16., 8.))\n",
    "bins = np.linspace(start=-0.5, stop=9.5, num=11, endpoint=True)\n",
    "bar_heights, _, _ = plt.hist(cifar10_train[1], bins=bins, \n",
    "         color=\"royalblue\", edgecolor=\"black\", alpha=0.8, \n",
    "         rwidth=0.9, align=\"mid\", label=\"Train\")\n",
    "plt.hist(cifar10_test[1], bins=bins, bottom=bar_heights,\n",
    "         color=\"salmon\", edgecolor=\"black\", alpha=0.8, \n",
    "         rwidth=0.9, align=\"mid\", label=\"Test\")\n",
    "plt.xticks(np.arange(10), labels=np.arange(10), \n",
    "           fontsize=14., fontweight=\"normal\")\n",
    "plt.legend(fontsize=14.)\n",
    "plt.title(\"Fashion MNIST Dataset\", fontsize=16., fontweight=\"bold\")\n",
    "plt.grid()\n",
    "plt.gca().set_axisbelow(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unscrambled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some of the images:\n",
    "image_gen = ScrambledImageDataGenerator( \n",
    "    features=cifar10_train[0][0:256,:,:],\n",
    "    labels=cifar10_train[1][0:256, 0],\n",
    "    batch_size=255,\n",
    "    scrambler_array=None,\n",
    "    normalize=False)\n",
    "\n",
    "custom_tile_image_plot( \n",
    "    (15,15),\n",
    "    image_gen[0][0],\n",
    "    labels=image_gen[0][1],\n",
    "    label_size=18.,\n",
    "    label_color=\"red\",\n",
    "    filename=\"\",\n",
    "    figure_size=(16., 16.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrambled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scrampled images:\n",
    "num_pixels = 32 * 32\n",
    "scrambler = np.linspace(\n",
    "    start=0, stop=num_pixels, num=num_pixels, \n",
    "    endpoint=False, dtype=np.int32)\n",
    "np.random.shuffle(scrambler)\n",
    "\n",
    "scrambled_image_gen = ScrambledImageDataGenerator(\n",
    "    features=cifar10_train[0][0:256,:,:],\n",
    "    labels=cifar10_train[1][0:256, 0],\n",
    "    batch_size=255,\n",
    "    scrambler_array=scrambler,\n",
    "    normalize=False)\n",
    " \n",
    "custom_tile_image_plot( \n",
    "    (15,15),\n",
    "    scrambled_image_gen[0][0],\n",
    "    labels=scrambled_image_gen[0][1],\n",
    "    label_size=18.,\n",
    "    label_color=\"red\",\n",
    "    filename=\"\",\n",
    "    figure_size=(16., 16.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unscramble Scrambled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscrambler = np.argsort(scrambler) \n",
    "\n",
    "unscrambled_images = np.zeros_like(scrambled_image_gen[0][0])\n",
    "for idx in range(unscrambled_images.shape[0]):\n",
    "    for c in range(3):\n",
    "        temp_array = scrambled_image_gen[0][0][idx, :, :, c].flatten()[unscrambler]\n",
    "        unscrambled_images[idx, :, :, c] = temp_array.reshape(\n",
    "            unscrambled_images.shape[1: -1])\n",
    "    \n",
    "custom_tile_image_plot( \n",
    "    (15,15),\n",
    "    unscrambled_images,\n",
    "    labels=scrambled_image_gen[0][1],\n",
    "    label_size=18.,\n",
    "    label_color=\"red\",\n",
    "    filename=\"\",\n",
    "    figure_size=(16., 16.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Model Constructor\n",
    "# def FCNClassifierModelConstructor( input_shape,\n",
    "#                                    numb_classes,\n",
    "#                                    hidden_layers_map={1:16,2:32,3:64,4:32,5:32,6:16,7:8},\n",
    "#                                    activation=tf.nn.relu              ):\n",
    "#     \"\"\"\n",
    "#     Constructs and retursn a fully connected tf.keras model.\n",
    "    \n",
    "#     Args:\n",
    "#         input_shape (tuple):      Input shape.\n",
    "#         numb_classes (int):       Number of classes (output layer size).\n",
    "#         hidden_layers_map (dict): If provided, the *hidden* layers are constructed as outlined. \n",
    "#                                   Note that this dictionary excludes the last layer!\n",
    "#         activation (tf.nn):       An instance of activation function.\n",
    "    \n",
    "#     Returns:\n",
    "#         tf.keras.model\n",
    "#     \"\"\"\n",
    "#     input_size=1\n",
    "#     for d in input_shape:\n",
    "#         input_size *= d\n",
    "#     #\n",
    "#     ## Construct model\n",
    "#     model_ = tf.keras.models.Sequential()\n",
    "#     model_.add( tf.keras.layers.Flatten( input_shape=input_shape,\n",
    "#                                          name=\"Flatten\" ) )\n",
    "#     for l in sorted(hidden_layers_map,reverse=False):\n",
    "#         if( l==1 ):\n",
    "#             model_.add( tf.keras.layers.Dense( hidden_layers_map[l],\n",
    "#                                                input_dim=input_size,\n",
    "#                                                activation=activation,\n",
    "#                                                use_bias=True,\n",
    "#                                                kernel_initializer='glorot_uniform',\n",
    "#                                                bias_initializer='zeros',\n",
    "#                                                kernel_regularizer=None,\n",
    "#                                                bias_regularizer=None,\n",
    "#                                                activity_regularizer=None,\n",
    "#                                                kernel_constraint=None,\n",
    "#                                                bias_constraint=None,\n",
    "#                                                name=\"Dense_\"+str(l)     ) )\n",
    "#         else:\n",
    "#             model_.add( tf.keras.layers.Dense(  hidden_layers_map[l],  \n",
    "#                                                 activation=activation,\n",
    "#                                                 use_bias=True,\n",
    "#                                                 kernel_initializer='glorot_uniform',\n",
    "#                                                 bias_initializer='zeros',\n",
    "#                                                 kernel_regularizer=None,\n",
    "#                                                 bias_regularizer=None,\n",
    "#                                                 activity_regularizer=None,\n",
    "#                                                 kernel_constraint=None,\n",
    "#                                                 bias_constraint=None,\n",
    "#                                                 name=\"Dense_\"+str(l)     ) )\n",
    "#     model_.add( tf.keras.layers.Dense(numb_classes, activation=tf.nn.softmax,name=\"Softmax\") )\n",
    "#     #\n",
    "#     return model_\n",
    "\n",
    "# def CNNClassifierModelConstructor( input_shape,\n",
    "#                                    numb_classes,\n",
    "#                                    cnn_layers_map={1:(16, (4,4), (1,1), (4,4), (1,1)),\n",
    "#                                                    2:(16, (4,4), (1,1), (4,4), (1,1)),\n",
    "#                                                    3:(16, (4,4), (1,1), (4,4), (1,1)),\n",
    "#                                                    4:(16, (4,4), (1,1), None,   None),\n",
    "#                                                    5:(16, (4,4), (1,1), None,   None) },\n",
    "#                                    fcn_layers_map={1:64,2:32},\n",
    "#                                    cnn_activation=tf.nn.relu,\n",
    "#                                    fcn_activation=tf.nn.relu,\n",
    "#                                    padding='valid',\n",
    "#                                    data_format='channels_last' ):\n",
    "#     \"\"\"\n",
    "#     Constructs and retursn a CNN tf.keras model.\n",
    "    \n",
    "#     Args:\n",
    "#         input_shape (tuple):    Input shape.\n",
    "#         numb_classes (int):     Number of classes (output layer size).\n",
    "#         cnn_layers_map (dict):  If provided, the *convolutional* layers are constructed as outlined. It is \n",
    "#                                 a dictionary with layer number as key and 5-dimensional tuple as value. The \n",
    "#                                 last two elements in the tuple are pertinent to the max pool layers. If set\n",
    "#                                 to None, max pooling will be skipped. \n",
    "#         fcn_layers_map (dict):  If provided, the *fully connected* layers are constructed as outlined.  \n",
    "#                                 Note that this dictionary excludes the last layer!\n",
    "#         cnn_activation (tf.nn): An instance of activation function.\n",
    "#         fcn_activation (tf.nn): An instance of activation function.\n",
    "#         padding (str):          Type of padding for CNN and MaxPool layers: 'valid' or 'simple'\n",
    "#         data_format (str):      Data format of the input:\n",
    "#                                        channels_first <---> (batch, height, width, channels)\n",
    "#                                        channels_last  <---> (batch, channels, height, width)\n",
    "    \n",
    "#     Returns:\n",
    "#         tf.keras.model\n",
    "#     \"\"\"\n",
    "#     model_ = tf.keras.models.Sequential()\n",
    "#     for l in sorted(cnn_layers_map,reverse=False):\n",
    "#         if( l==1 ):\n",
    "#             model_.add( tf.keras.layers.Conv2D( input_shape=input_shape,\n",
    "#                                                 filters=cnn_layers_map[l][0],\n",
    "#                                                 kernel_size=cnn_layers_map[l][1],\n",
    "#                                                 strides=cnn_layers_map[l][2],\n",
    "#                                                 padding=padding,\n",
    "#                                                 data_format=data_format,\n",
    "#                                                 dilation_rate=(1,1),\n",
    "#                                                 activation=cnn_activation,\n",
    "#                                                 use_bias=True,\n",
    "#                                                 kernel_initializer='glorot_uniform',\n",
    "#                                                 bias_initializer='zeros',\n",
    "#                                                 kernel_regularizer=None,\n",
    "#                                                 bias_regularizer=None,\n",
    "#                                                 activity_regularizer=None,\n",
    "#                                                 kernel_constraint=None,\n",
    "#                                                 bias_constraint=None,\n",
    "#                                                 name=\"CNN_\"+str(l)     ) )\n",
    "#             if( cnn_layers_map[l][3] is not None ):\n",
    "#                 model_.add( tf.keras.layers.MaxPool2D( pool_size=cnn_layers_map[l][3],\n",
    "#                                                        strides=cnn_layers_map[l][4],\n",
    "#                                                        padding=padding,\n",
    "#                                                        data_format=None, \n",
    "#                                                        name=\"MaxPool_\"+str(l)     ) )\n",
    "            \n",
    "#         else:\n",
    "#             model_.add( tf.keras.layers.Conv2D( filters=cnn_layers_map[l][0],\n",
    "#                                                 kernel_size=cnn_layers_map[l][1],\n",
    "#                                                 strides=cnn_layers_map[l][2],\n",
    "#                                                 padding=padding,\n",
    "#                                                 data_format=data_format,\n",
    "#                                                 dilation_rate=(1,1),\n",
    "#                                                 activation=cnn_activation,\n",
    "#                                                 use_bias=True,\n",
    "#                                                 kernel_initializer='glorot_uniform',\n",
    "#                                                 bias_initializer='zeros',\n",
    "#                                                 kernel_regularizer=None,\n",
    "#                                                 bias_regularizer=None,\n",
    "#                                                 activity_regularizer=None,\n",
    "#                                                 kernel_constraint=None,\n",
    "#                                                 bias_constraint=None,\n",
    "#                                                 name=\"CNN_\"+str(l)     ) )\n",
    "#             if( cnn_layers_map[l][3] is not None ):\n",
    "#                 model_.add( tf.keras.layers.MaxPool2D( pool_size=cnn_layers_map[l][3],\n",
    "#                                                        strides=cnn_layers_map[l][4],\n",
    "#                                                        padding=padding,\n",
    "#                                                        data_format=None, \n",
    "#                                                        name=\"MaxPool_\"+str(l)     ) )\n",
    "#     model_.add(tf.keras.layers.Flatten( name=\"Flatten\" ))\n",
    "#     for l in sorted(fcn_layers_map,reverse=False):\n",
    "#         model_.add( tf.keras.layers.Dense(  fcn_layers_map[l],  \n",
    "#                                             activation=fcn_activation,\n",
    "#                                             use_bias=True,\n",
    "#                                             kernel_initializer='glorot_uniform',\n",
    "#                                             bias_initializer='zeros',\n",
    "#                                             kernel_regularizer=None,\n",
    "#                                             bias_regularizer=None,\n",
    "#                                             activity_regularizer=None,\n",
    "#                                             kernel_constraint=None,\n",
    "#                                             bias_constraint=None,\n",
    "#                                             name=\"Dense_\"+str(l+len(cnn_layers_map))    ) )\n",
    "#     ## Last layer:\n",
    "#     model_.add( tf.keras.layers.Dense(numb_classes, activation=tf.nn.softmax,name=\"Softmax\") )\n",
    "#     #\n",
    "#     return model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CASE Ia: FCN Without scrambling:\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#\n",
    "## Construct a model\n",
    "fcn_wo_model = FCNClassifierModelConstructor( input_shape=(28,28),\n",
    "                                              numb_classes=10,\n",
    "                                              hidden_layers_map={1:512, 2:256, 3:128, 4:64},\n",
    "                                              activation=tf.nn.relu )\n",
    "print( fcn_wo_model.summary() )\n",
    "print( \"_\"*32, end=\"\\n\\n\" )\n",
    "#\n",
    "## Compiling the model:\n",
    "fcn_wo_model.compile( optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy']  )\n",
    "#\n",
    "## We add a tensorboard callback:\n",
    "tbCallBack = tf.keras.callbacks.TensorBoard( log_dir='./MNIST_FCN_WO_Scrambling',\n",
    "                                             histogram_freq=1,\n",
    "                                             batch_size=32, \n",
    "                                             write_graph=True, \n",
    "                                             write_images=True,\n",
    "                                             write_grads=True,\n",
    "                                             update_freq='epoch')\n",
    "#\n",
    "## Early stopping callback to prevent overfitting:\n",
    "earlystopCallback = tf.keras.callbacks.EarlyStopping( monitor='val_loss',\n",
    "                                                      min_delta=0.001,\n",
    "                                                      patience=10,\n",
    "                                                      verbose=0,\n",
    "                                                      mode='auto',\n",
    "                                                      baseline=None,\n",
    "                                                      restore_best_weights=True )\n",
    "#\n",
    "## Construct generators for training and validation:\n",
    "tv_idx_split = int(0.8*mnist_x_train.shape[0])\n",
    "train_generator = DataGenerator( features=mnist_x_train[0:tv_idx_split,:,:],\n",
    "                                 labels=mnist_y_train[0:tv_idx_split],\n",
    "                                 batch_size=32,\n",
    "                                 scrambler_array=None,\n",
    "                                 normalize=True )\n",
    "validation_generator = DataGenerator( features=mnist_x_train[tv_idx_split:,:,:],\n",
    "                                      labels=mnist_y_train[tv_idx_split:],\n",
    "                                      batch_size=32,\n",
    "                                      scrambler_array=None,\n",
    "                                      normalize=True )\n",
    "print( \"Training Length:   \" , len(train_generator)      )\n",
    "print( \"Validation Length: \" , len(validation_generator) )\n",
    "print( \"_\"*32, end=\"\\n\\n\" )\n",
    "#\n",
    "## Trainig Time!\n",
    "##==============\n",
    "fcn_wo_model.fit_generator( generator=train_generator,\n",
    "                            steps_per_epoch=None,\n",
    "                            epochs=10000,\n",
    "                            verbose=2,\n",
    "                            callbacks=[earlystopCallback,tbCallBack],\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=None,\n",
    "                            class_weight=None,\n",
    "                            max_queue_size=100,\n",
    "                            workers=8,\n",
    "                            use_multiprocessing=True,\n",
    "                            initial_epoch=0    )\n",
    "print( \"_\"*32, end=\"\\n\\n\" )\n",
    "#\n",
    "## Testing Time!\n",
    "##==============\n",
    "fcn_wo_model.evaluate( x=mnist_x_test,\n",
    "                       y=mnist_y_test,\n",
    "                       batch_size=None,\n",
    "                       verbose=1,\n",
    "                       sample_weight=None,\n",
    "                       steps=None,\n",
    "                       callbacks=None,\n",
    "                       max_queue_size=10,\n",
    "                       workers=8,\n",
    "                       use_multiprocessing=True  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator( features=mnist_x_test,\n",
    "                                labels=mnist_y_test,\n",
    "                                batch_size=1,\n",
    "                                scrambler_array=None,\n",
    "                                normalize=True )\n",
    "print( \"Test Length: \" , len(test_generator) )\n",
    "y_predict = fcn_wo_model.predict_generator( generator=test_generator,\n",
    "                                            steps=None,\n",
    "                                            callbacks=None,\n",
    "                                            max_queue_size=10,\n",
    "                                            workers=8,\n",
    "                                            use_multiprocessing=True,\n",
    "                                            verbose=0  )\n",
    "CustomTilePlotWithHistogram( (10,10), \n",
    "                             images=mnist_x_test, \n",
    "                             labels=mnist_y_test,\n",
    "                             predictions=y_predict,\n",
    "                             classes=np.linspace(start=0,stop=10,num=10,endpoint=False,dtype=np.uint8),\n",
    "                             only_mispredicted=True,\n",
    "                             filename='', \n",
    "                             cmap='gray', \n",
    "                             label_size=32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CASE IIa: FCN Without scrambling:\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#\n",
    "## Construct a model\n",
    "fcn_w_model = FCNClassifierModelConstructor( input_shape=(28,28),\n",
    "                                             numb_classes=10,\n",
    "                                             hidden_layers_map={1:512, 2:256, 3:128, 4:64},\n",
    "                                             activation=tf.nn.relu )\n",
    "print( fcn_w_model.summary() )\n",
    "print( \"_\"*32, end=\"\\n\\n\" )\n",
    "#\n",
    "## Compiling the model:\n",
    "fcn_w_model.compile( optimizer='adam',\n",
    "                     loss='sparse_categorical_crossentropy',\n",
    "                     metrics=['accuracy']  )\n",
    "#\n",
    "## We add a tensorboard callback:\n",
    "tbCallBack = tf.keras.callbacks.TensorBoard( log_dir='./MNIST_FCN_W_Scrambling',\n",
    "                                             histogram_freq=1,\n",
    "                                             batch_size=32, \n",
    "                                             write_graph=True, \n",
    "                                             write_images=True,\n",
    "                                             write_grads=True,\n",
    "                                             update_freq='epoch')\n",
    "#\n",
    "## Early stopping callback to prevent overfitting:\n",
    "earlystopCallback = tf.keras.callbacks.EarlyStopping( monitor='val_loss',\n",
    "                                                      min_delta=0.001,\n",
    "                                                      patience=10,\n",
    "                                                      verbose=0,\n",
    "                                                      mode='auto',\n",
    "                                                      baseline=None,\n",
    "                                                      restore_best_weights=True )\n",
    "#\n",
    "## Construct generators for training and validation:\n",
    "tv_idx_split = int(0.8*mnist_x_train.shape[0])\n",
    "train_generator = DataGenerator( features=mnist_x_train[0:tv_idx_split,:,:],\n",
    "                                 labels=mnist_y_train[0:tv_idx_split],\n",
    "                                 batch_size=32,\n",
    "                                 scrambler_array=mnist_scrambler,\n",
    "                                 normalize=True )\n",
    "validation_generator = DataGenerator( features=mnist_x_train[tv_idx_split:,:,:],\n",
    "                                      labels=mnist_y_train[tv_idx_split:],\n",
    "                                      batch_size=32,\n",
    "                                      scrambler_array=mnist_scrambler,\n",
    "                                      normalize=True )\n",
    "print( \"Training Length:   \" , len(train_generator)      )\n",
    "print( \"Validation Length: \" , len(validation_generator) )\n",
    "print( \"_\"*32, end=\"\\n\\n\" )\n",
    "#\n",
    "## Trainig Time!\n",
    "##==============\n",
    "fcn_w_model.fit_generator( generator=train_generator,\n",
    "                           steps_per_epoch=None,\n",
    "                           epochs=10000,\n",
    "                           verbose=2,\n",
    "                           callbacks=[earlystopCallback,tbCallBack],\n",
    "                           validation_data=validation_generator,\n",
    "                           validation_steps=None,\n",
    "                           class_weight=None,\n",
    "                           max_queue_size=100,\n",
    "                           workers=8,\n",
    "                           use_multiprocessing=True,\n",
    "                           initial_epoch=0    )\n",
    "print( \"_\"*32, end=\"\\n\\n\" )\n",
    "#\n",
    "## Testing Time!\n",
    "##==============\n",
    "test_generator = DataGenerator( features=mnist_x_test,\n",
    "                                labels=mnist_y_test,\n",
    "                                batch_size=32,\n",
    "                                scrambler_array=mnist_scrambler,\n",
    "                                normalize=True )\n",
    "print( \"Test Length: \" , len(test_generator) )\n",
    "fcn_w_model.evaluate_generator( test_generator,\n",
    "                                steps=None,\n",
    "                                callbacks=None,\n",
    "                                max_queue_size=10,\n",
    "                                workers=8,\n",
    "                                use_multiprocessing=True,\n",
    "                                verbose=0  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## CASE Ib: CCN WITHOUT scrambling:\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#\n",
    "## Construct a model\n",
    "ccn_wo_model = CNNClassifierModelConstructor( input_shape=(28,28,1),\n",
    "                                              numb_classes=10,\n",
    "                                              cnn_layers_map={1:(32, (4,4), (1,1), (8,8), (1,1)),\n",
    "                                                              2:(16, (4,4), (1,1), (4,4), (1,1)),\n",
    "                                                              3:(8,  (4,4), (1,1), (2,2), (1,1)) },\n",
    "                                              fcn_layers_map={1:64,2:32},\n",
    "                                              cnn_activation=tf.nn.relu,\n",
    "                                              fcn_activation=tf.nn.relu,\n",
    "                                              padding='valid',\n",
    "                                              data_format='channels_last' )\n",
    "print( ccn_wo_model.summary() )\n",
    "print( \"_\"*32, end=\"\\n\\n\" )\n",
    "#\n",
    "## Compiling the model:\n",
    "ccn_wo_model.compile( optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy']  )\n",
    "#\n",
    "## We add a tensorboard callback:\n",
    "tbCallBack = tf.keras.callbacks.TensorBoard( log_dir='./MNIST_CCN_WO_Scrambling',\n",
    "                                             histogram_freq=1,\n",
    "                                             batch_size=32, \n",
    "                                             write_graph=True, \n",
    "                                             write_images=True,\n",
    "                                             write_grads=True,\n",
    "                                             update_freq='epoch')\n",
    "#\n",
    "## Early stopping callback to prevent overfitting:\n",
    "earlystopCallback = tf.keras.callbacks.EarlyStopping( monitor='val_loss',\n",
    "                                                      min_delta=0.001,\n",
    "                                                      patience=10,\n",
    "                                                      verbose=0,\n",
    "                                                      mode='auto',\n",
    "                                                      baseline=None,\n",
    "                                                      restore_best_weights=True )\n",
    "#\n",
    "## Construct generators for training and validation:\n",
    "tv_idx_split = int(0.8*mnist_x_train.shape[0])\n",
    "train_generator = DataGenerator( features=mnist_x_train[0:tv_idx_split,:,:,np.newaxis],\n",
    "                                 labels=mnist_y_train[0:tv_idx_split],\n",
    "                                 batch_size=32,\n",
    "                                 scrambler_array=None,\n",
    "                                 normalize=True )\n",
    "validation_generator = DataGenerator( features=mnist_x_train[tv_idx_split:,:,:,np.newaxis],\n",
    "                                      labels=mnist_y_train[tv_idx_split:],\n",
    "                                      batch_size=32,\n",
    "                                      scrambler_array=None,\n",
    "                                      normalize=True )\n",
    "print( \"Training Length:   \" , len(train_generator)      )\n",
    "print( \"Validation Length: \" , len(validation_generator) )\n",
    "print( \"_\"*32, end=\"\\n\\n\" )\n",
    "#\n",
    "## Trainig Time!\n",
    "##==============\n",
    "ccn_wo_model.fit_generator( generator=train_generator,\n",
    "                            steps_per_epoch=None,\n",
    "                            epochs=10000,\n",
    "                            verbose=2,\n",
    "                            callbacks=[earlystopCallback,tbCallBack],\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=None,\n",
    "                            class_weight=None,\n",
    "                            max_queue_size=100,\n",
    "                            workers=8,\n",
    "                            use_multiprocessing=True,\n",
    "                            initial_epoch=0    )\n",
    "#\n",
    "## Testing Time!\n",
    "##==============\n",
    "ccn_wo_model.evaluate( x=mnist_x_test[:,:,:,np.newaxis],\n",
    "                       y=mnist_y_test,\n",
    "                       batch_size=None,\n",
    "                       verbose=1,\n",
    "                       sample_weight=None,\n",
    "                       steps=None,\n",
    "                       callbacks=None,\n",
    "                       max_queue_size=10,\n",
    "                       workers=8,\n",
    "                       use_multiprocessing=True  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_generator = DataGenerator( features=mnist_x_test[:,:,:,np.newaxis],\n",
    "#                                 labels=mnist_y_test,\n",
    "#                                 batch_size=1,\n",
    "#                                 scrambler_array=None,\n",
    "#                                 normalize=True )\n",
    "# print( \"Test Length: \" , len(test_generator) )\n",
    "# y_predict = ccn_wo_model.predict_generator( generator=test_generator,\n",
    "#                                             steps=None,\n",
    "#                                             callbacks=None,\n",
    "#                                             max_queue_size=10,\n",
    "#                                             workers=8,\n",
    "#                                             use_multiprocessing=True,\n",
    "#                                             verbose=0  )\n",
    "y_predict = ccn_wo_model.predict( x=mnist_x_test[:,:,:,np.newaxis],\n",
    "                                  batch_size=None,\n",
    "                                  verbose=0,\n",
    "                                  steps=None,\n",
    "                                  callbacks=None,\n",
    "                                  max_queue_size=10,\n",
    "                                  workers=8,\n",
    "                                  use_multiprocessing=True )\n",
    "CustomTilePlotWithHistogram( (10,10), \n",
    "                             images=mnist_x_test, \n",
    "                             labels=mnist_y_test,\n",
    "                             predictions=y_predict,\n",
    "                             classes=np.linspace(start=0,stop=10,num=10,endpoint=False,dtype=np.uint8),\n",
    "                             only_mispredicted=True,\n",
    "                             filename='', \n",
    "                             cmap='gray', \n",
    "                             label_size=32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CASE IIb: CCN WITH scrambling:\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#\n",
    "## Construct a model\n",
    "ccn_w_model = CNNClassifierModelConstructor( input_shape=(28,28,1),\n",
    "                                             numb_classes=10,\n",
    "                                             cnn_layers_map={1:(32, (4,4), (1,1), (8,8), (1,1)),\n",
    "                                                             2:(16, (4,4), (1,1), (4,4), (1,1)),\n",
    "                                                             3:(8,  (4,4), (1,1), (2,2), (1,1)) },\n",
    "                                             fcn_layers_map={1:64,2:32},\n",
    "                                             cnn_activation=tf.nn.relu,\n",
    "                                             fcn_activation=tf.nn.relu,\n",
    "                                             padding='valid',\n",
    "                                             data_format='channels_last' )\n",
    "print( ccn_w_model.summary() )\n",
    "print( \"_\"*32, end=\"\\n\\n\" )\n",
    "#\n",
    "## Compiling the model:\n",
    "ccn_w_model.compile( optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy']  )\n",
    "#\n",
    "## We add a tensorboard callback:\n",
    "tbCallBack = tf.keras.callbacks.TensorBoard( log_dir='./MNIST_CCN_W_Scrambling',\n",
    "                                             histogram_freq=1,\n",
    "                                             batch_size=32, \n",
    "                                             write_graph=True, \n",
    "                                             write_images=True,\n",
    "                                             write_grads=True,\n",
    "                                             update_freq='epoch')\n",
    "#\n",
    "## Early stopping callback to prevent overfitting:\n",
    "earlystopCallback = tf.keras.callbacks.EarlyStopping( monitor='val_loss',\n",
    "                                                      min_delta=0.001,\n",
    "                                                      patience=10,\n",
    "                                                      verbose=0,\n",
    "                                                      mode='auto',\n",
    "                                                      baseline=None,\n",
    "                                                      restore_best_weights=True )\n",
    "#\n",
    "## Construct generators for training and validation:\n",
    "tv_idx_split = int(0.8*mnist_x_train.shape[0])\n",
    "train_generator = DataGenerator( features=mnist_x_train[0:tv_idx_split,:,:,np.newaxis],\n",
    "                                 labels=mnist_y_train[0:tv_idx_split],\n",
    "                                 batch_size=32,\n",
    "                                 scrambler_array=mnist_scrambler,\n",
    "                                 normalize=True )\n",
    "validation_generator = DataGenerator( features=mnist_x_train[tv_idx_split:,:,:,np.newaxis],\n",
    "                                      labels=mnist_y_train[tv_idx_split:],\n",
    "                                      batch_size=32,\n",
    "                                      scrambler_array=mnist_scrambler,\n",
    "                                      normalize=True )\n",
    "print( \"Training Length:   \" , len(train_generator)      )\n",
    "print( \"Validation Length: \" , len(validation_generator) )\n",
    "print( \"_\"*32, end=\"\\n\\n\" )\n",
    "#\n",
    "## Trainig Time!\n",
    "##==============\n",
    "ccn_w_model.fit_generator( generator=train_generator,\n",
    "                           steps_per_epoch=None,\n",
    "                           epochs=10000,\n",
    "                           verbose=2,\n",
    "                           callbacks=[earlystopCallback,tbCallBack],\n",
    "                           validation_data=validation_generator,\n",
    "                           validation_steps=None,\n",
    "                           class_weight=None,\n",
    "                           max_queue_size=100,\n",
    "                           workers=8,\n",
    "                           use_multiprocessing=True,\n",
    "                           initial_epoch=0    )\n",
    "#\n",
    "## Testing Time!\n",
    "##==============\n",
    "test_generator = DataGenerator( features=mnist_x_test[:,:,:,np.newaxis],\n",
    "                                labels=mnist_y_test,\n",
    "                                batch_size=32,\n",
    "                                scrambler_array=mnist_scrambler,\n",
    "                                normalize=True )\n",
    "print( \"Test Length: \" , len(test_generator) )\n",
    "ccn_w_model.evaluate_generator( test_generator,\n",
    "                                steps=None,\n",
    "                                callbacks=None,\n",
    "                                max_queue_size=10,\n",
    "                                workers=8,\n",
    "                                use_multiprocessing=True,\n",
    "                                verbose=0  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
